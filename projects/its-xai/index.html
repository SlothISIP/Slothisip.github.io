<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>ITS AI XAI - Explainable PCB Defect Detection | Ju O Kim</title>

    <meta name="description" content="AI-powered PCB defect detection with 603 sensor features, SHAP explainability, 94.62% F1-score, 67.3ms latency.">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Ju O Kim">
    <link rel="canonical" href="https://slothisip.github.io/projects/its-xai/">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://slothisip.github.io/projects/its-xai/">
    <meta property="og:title" content="ITS AI XAI - Explainable PCB Defect Detection">
    <meta property="og:description" content="Multimodal fusion (603 features + vision) with SHAP explainability: 94.62% F1-score, 67.3ms latency.">
    <meta property="og:image" content="https://slothisip.github.io/images/its_xai_thumb.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:site_name" content="Ju O Kim - Portfolio">

    <!-- Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:url" content="https://slothisip.github.io/projects/its-xai/">
    <meta name="twitter:title" content="ITS AI XAI - Explainable PCB Defect Detection">
    <meta name="twitter:description" content="Multimodal fusion with SHAP explainability: 94.62% F1-score, 67.3ms latency.">
    <meta name="twitter:image" content="https://slothisip.github.io/images/its_xai_thumb.png">
    <meta name="twitter:image:alt" content="ITS XAI SHAP feature importance visualization">

    <link rel="shortcut icon" href="../../images/favicon/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                ITS AI XAI: Intelligent Testing System<br>with Explainable AI
                <small>
                    F1: 0.9462 | Latency: 67.3ms | Production Ready
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="../../index.html">
                          Ju O Kim
                        </a>
                        </br>Keimyung University
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Overview
                </h3>
                <p class="text-justify">
                    I designed and built ITS_AI_XAI as a solo developer handling both backend and frontend end-to-end, with guidance from my team manager. This production-ready AI system serves PCB manufacturing quality control. I engineered the multimodal fusion pipeline combining 603 sensor features with YOLOv11 visual inspection, achieving F1-score of 0.9462 with 67.3ms latency. I implemented SHAP and counterfactual explanations to provide interpretability for manufacturing engineers.
                </p>
                <div style="background: #f8f9fa; border-left: 4px solid #007bff; padding: 15px; margin: 15px 0;">
                    <p style="margin: 0;"><strong>Note:</strong> This project was developed for industrial clients under NDA. Specific client names and proprietary datasets have been anonymized. The methodology and architecture described here accurately represent my contributions.</p>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    My Contributions
                </h3>
                <ul>
                    <li><strong>System Architecture:</strong> I designed the complete multimodal fusion architecture combining sensor data with computer vision</li>
                    <li><strong>Feature Engineering:</strong> I implemented the feature selection pipeline reducing 603 raw sensor features to optimal predictive subset using mutual information filtering</li>
                    <li><strong>ML Pipeline:</strong> I built the XGBoost meta-classifier fusing Random Forest (sensor) predictions with YOLOv11 (vision) detection outputs</li>
                    <li><strong>XAI Implementation:</strong> I developed the complete explainability layer including SHAP waterfall, LIME comparisons, and counterfactual analysis interface</li>
                    <li><strong>Frontend Development:</strong> I built the 4-tab Streamlit dashboard with Plotly visualizations for real-time defect analysis</li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    System Architecture
                </h3>
                <center>
                    <img src="images/architecture.svg" class="img-responsive" alt="System Architecture" style="max-width: 100%; background: #1a1a2e; border-radius: 8px; padding: 10px;">
                </center>
                <br>
                <p class="text-justify">
                    I designed this multimodal fusion pipeline architecture combining 603 sensor features with YOLOv11 visual detection. I implemented Random Forest for sensor data processing and built the Feature Selection module to filter key predictors. I developed the XGBoost meta-classifier that fuses both streams achieving F1 0.9462. I also created the complete XAI layer providing SHAP, LIME, and counterfactual explanations for production decision support.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    SHAP Waterfall Explanation
                </h3>
                <center>
                    <img src="images/ITS_AI_1.png" class="img-responsive" alt="SHAP Waterfall Explanation">
                </center>
                <br>
                <p class="text-justify">
                    Detailed SHAP waterfall visualization showing individual feature contributions to the model's prediction. Each bar represents a feature's impact, with red arrows indicating features pushing toward DEFECT and blue arrows showing features pushing toward PASS. The cumulative effect determines the final classification outcome.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Counterfactual Analysis Interface
                </h3>
                <center>
                    <img src="images/ITS_AI_2.png" class="img-responsive" alt="Counterfactual Analysis Interface">
                </center>
                <br>
                <p class="text-justify">
                    Interactive counterfactual analysis interface enabling engineers to explore "what-if" scenarios. The system identifies minimal parameter changes needed to flip predictions, providing actionable process optimization recommendations for manufacturing quality improvement.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    LIME vs SHAP Comparison
                </h3>
                <center>
                    <img src="images/ITS_AI_3.png" class="img-responsive" alt="LIME vs SHAP Comparison">
                </center>
                <br>
                <p class="text-justify">
                    Side-by-side comparison of LIME (Local Interpretable Model-agnostic Explanations) and SHAP explanation methods. This visualization demonstrates how different XAI techniques interpret the same prediction, validating explanation consistency and providing confidence in feature importance rankings.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    XGBoost Training Pipeline
                </h3>
                <center>
                    <img src="images/ITS_AI_4.png" class="img-responsive" alt="XGBoost Training Pipeline">
                </center>
                <br>
                <p class="text-justify">
                    Complete XGBoost meta-classifier training pipeline visualization showing data preprocessing, cross-validation, hyperparameter tuning, and model evaluation stages. The pipeline integrates Random Forest sensor analysis with YOLOv11 visual detection to achieve the 0.9462 F1-score.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Feature Selection Pipeline
                </h3>
                <center>
                    <img src="images/ITS_AI_5.png" class="img-responsive" alt="Feature Selection Pipeline">
                </center>
                <br>
                <p class="text-justify">
                    Automated feature selection pipeline reducing 603 raw sensor features to the most predictive subset. Combines statistical filtering, recursive feature elimination, and importance-based selection to optimize model performance while maintaining interpretability.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Key Technical Decisions
                </h3>
                <table class="table table-bordered" style="font-size: 0.9em;">
                    <tbody>
                        <tr>
                            <td style="width: 25%;"><strong>Decision</strong></td>
                            <td><strong>XGBoost Meta-Classifier over End-to-End Deep Learning</strong></td>
                        </tr>
                        <tr>
                            <td><strong>Context</strong></td>
                            <td>Manufacturing engineers require interpretable predictions for root cause analysis</td>
                        </tr>
                        <tr>
                            <td><strong>Options</strong></td>
                            <td>End-to-end neural network vs. Two-stage fusion with XGBoost meta-classifier</td>
                        </tr>
                        <tr>
                            <td><strong>Rationale</strong></td>
                            <td>XGBoost enables SHAP feature attribution at prediction time (3.1ms/sample), while deep learning would require expensive gradient-based explanations; equivalent accuracy with 67.3ms total latency</td>
                        </tr>
                    </tbody>
                </table>
                <table class="table table-bordered" style="font-size: 0.9em;">
                    <tbody>
                        <tr>
                            <td style="width: 25%;"><strong>Decision</strong></td>
                            <td><strong>SHAP + LIME Dual Explanation</strong></td>
                        </tr>
                        <tr>
                            <td><strong>Context</strong></td>
                            <td>Single explanation method may have biases; engineers need confidence in feature importance</td>
                        </tr>
                        <tr>
                            <td><strong>Options</strong></td>
                            <td>SHAP only vs. LIME only vs. Both with consistency validation</td>
                        </tr>
                        <tr>
                            <td><strong>Rationale</strong></td>
                            <td>Dual explanation with 94% top-5 feature agreement provides higher confidence; disagreements flag edge cases requiring human review</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Technical Specifications
                </h3>
                <table class="table table-bordered">
                    <tbody>
                        <tr>
                            <td><strong>Meta-Classifier F1</strong></td>
                            <td>0.9462 (+26% above target)</td>
                        </tr>
                        <tr>
                            <td><strong>API Latency</strong></td>
                            <td>67.3ms (45% faster than target)</td>
                        </tr>
                        <tr>
                            <td><strong>YOLO mAP@50</strong></td>
                            <td>93.51%</td>
                        </tr>
                        <tr>
                            <td><strong>Recall</strong></td>
                            <td>95.91%</td>
                        </tr>
                        <tr>
                            <td><strong>ML/AI Stack</strong></td>
                            <td>XGBoost, Random Forest, YOLOv11, SHAP</td>
                        </tr>
                        <tr>
                            <td><strong>Dashboard</strong></td>
                            <td>Streamlit, Plotly (4 interactive tabs)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

    </div>
</body>
</html>
